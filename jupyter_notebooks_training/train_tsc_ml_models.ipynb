{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cgmquantify as cgm\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "from datetime import date\n",
    "from scipy.stats import stats\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import stats\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cgmquantify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c4cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tslearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e12220",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87902116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_all = pd.read_csv('df_overnight_and_PRO.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b688b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_all = df_merged_all.dropna(subset=['axis1', 'axis2', 'axis3'],how='all')\n",
    "\n",
    "df_merged_all['axis1'] = df_merged_all['axis1'].fillna(0)\n",
    "df_merged_all['axis2'] = df_merged_all['axis2'].fillna(0)\n",
    "df_merged_all['axis3'] = df_merged_all['axis3'].fillna(0)\n",
    "\n",
    "df_merged_all['time'] = pd.to_datetime(df_merged_all['time'] ,errors = 'coerce')\n",
    "\n",
    "df_merged_all = df_merged_all.reset_index(drop=True)\n",
    "df_merged_all = df_merged_all.drop([\"Unnamed: 0\", \"joinID\"], axis=1)\n",
    "\n",
    "fasting_states_to_keep = ['fasting', 'non-fasting']\n",
    "df_merged_all = df_merged_all[df_merged_all.label.isin(fasting_states_to_keep)]\n",
    "\n",
    "#phases_to_keep = ['lTRE', 'eTRE']\n",
    "#df_merged_all = df_merged_all[df_merged_all.phase.isin(phases_to_keep)]\n",
    "\n",
    "final_df = df_merged_all.sort_values(by=['id', 'time', \"phase\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Time'] = pd.to_datetime(final_df['time'], format='%Y-%m-%dT%H:%M:%S')\n",
    "final_df['Glucose'] = pd.to_numeric(final_df['gl'])\n",
    "final_df['Day'] = final_df[\"Time\"].dt.date\n",
    "final_df = final_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef79d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = final_df[final_df['id'] > 8]\n",
    "df_test = final_df[final_df['id'] <= 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a70d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test = [2, 10, 12, 17, 19, 23, 35, 34, 38, 41, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78789591",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = final_df.loc[final_df['id'].isin(id_test)] \n",
    "df_train = final_df.loc[~final_df['id'].isin(id_test)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753f377c",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f86c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {\"non-fasting\": 1, \"fasting\":0}\n",
    "df_train[\"label\"] = df_train[\"label\"].map(map_dict)\n",
    "df_test[\"label\"] = df_test[\"label\"].map(map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33918405",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {\"screening\": 1, \"lTRE\":0, \"eTRE\":2}\n",
    "df_train[\"phase\"] = df_train[\"phase\"].map(map_dict)\n",
    "df_test[\"phase\"] = df_test[\"phase\"].map(map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a84e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee2fda",
   "metadata": {},
   "source": [
    "## Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6463938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list_train = []\n",
    "train_labels = []\n",
    "\n",
    "\n",
    "window_size = 3\n",
    "step_size = 1\n",
    "\n",
    "# creating overlaping windows of size window-size 100\n",
    "for i in range(0, df_train.shape[0] - window_size, step_size):\n",
    "    id_p = df_train['id'].values[i: i + window_size]\n",
    "    phase = df_train['phase'].values[i: i + window_size]\n",
    "    time = df_train['Time'].values[i: i + window_size]\n",
    "    times = df_train['Day'].values[i: i + window_size]\n",
    "    gls = df_train['Glucose'].values[i: i + window_size]\n",
    "    steps = df_train['steps'].values[i: i + window_size]\n",
    "    inclineStanding = df_train['inclineStanding'].values[i: i + window_size]\n",
    "    inclineSitting = df_train['inclineSitting'].values[i: i + window_size]\n",
    "    inclineLying = df_train['inclineLying'].values[i: i + window_size]\n",
    "    \n",
    "    timedelta_first = time[1] - time[0]\n",
    "    timedelta_second = time[2] - time[1]\n",
    "    one_hour = 3600000000000\n",
    "    \n",
    "    if (timedelta_first < one_hour and timedelta_second < one_hour):\n",
    "   \n",
    "    \n",
    "        xs = df_train['axis1'].values[i: i + window_size]\n",
    "        ys = df_train['axis2'].values[i: i + window_size]\n",
    "        zs = df_train['axis3'].values[i: i + window_size]\n",
    "\n",
    "        label = stats.mode(df_train['label'][i: i + window_size])[0][0]\n",
    "\n",
    "        df_slice = pd.DataFrame(time, columns=['Time'])\n",
    "        df_slice[\"id\"] = id_p\n",
    "        df_slice[\"phase\"] = phase\n",
    "        df_slice[\"Day\"] = times\n",
    "        df_slice[\"Glucose\"] = gls   \n",
    "        df_slice[\"axis1\"] = xs\n",
    "        df_slice[\"axis2\"] = ys\n",
    "        df_slice[\"axis3\"] = zs\n",
    "        df_slice[\"steps\"] = steps\n",
    "        df_slice[\"inclineStanding\"] = inclineStanding\n",
    "        df_slice[\"inclineSitting\"] = inclineSitting\n",
    "        df_slice[\"inclineLying\"] = inclineLying\n",
    "\n",
    "        x_list_train.append(df_slice)\n",
    "\n",
    "        train_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544030c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list_test = []\n",
    "test_labels = []\n",
    "\n",
    "\n",
    "window_size = 3\n",
    "step_size = 1\n",
    "\n",
    "# creating overlaping windows of size window-size 100\n",
    "for i in range(0, df_test.shape[0] - window_size, step_size):\n",
    "    id_p = df_test['id'].values[i: i + window_size]\n",
    "    phase = df_test['phase'].values[i: i + window_size]\n",
    "    time = df_test['Time'].values[i: i + window_size]\n",
    "    times = df_test['Day'].values[i: i + window_size]\n",
    "    gls = df_test['Glucose'].values[i: i + window_size]\n",
    "    steps = df_train['steps'].values[i: i + window_size]\n",
    "    inclineStanding = df_test['inclineStanding'].values[i: i + window_size]\n",
    "    inclineSitting = df_test['inclineSitting'].values[i: i + window_size]\n",
    "    inclineLying = df_test['inclineLying'].values[i: i + window_size]\n",
    "    \n",
    "    timedelta_first = time[1] - time[0]\n",
    "    timedelta_second = time[2] - time[1]\n",
    "    one_hour = 3600000000000\n",
    "    \n",
    "    if (timedelta_first < one_hour and timedelta_second < one_hour):\n",
    "    \n",
    "        xs = df_test['axis1'].values[i: i + window_size]\n",
    "        ys = df_test['axis2'].values[i: i + window_size]\n",
    "        zs = df_test['axis3'].values[i: i + window_size]\n",
    "\n",
    "        label = stats.mode(df_test['label'][i: i + window_size])[0][0]\n",
    "\n",
    "        df_slice = pd.DataFrame(time, columns=['Time'])\n",
    "        df_slice[\"id\"] = id_p\n",
    "        df_slice[\"phase\"] = phase\n",
    "        df_slice[\"Day\"] = times\n",
    "        df_slice[\"Glucose\"] = gls     \n",
    "        df_slice[\"axis1\"] = xs\n",
    "        df_slice[\"axis2\"] = ys\n",
    "        df_slice[\"axis3\"] = zs\n",
    "        df_slice[\"steps\"] = steps\n",
    "        df_slice[\"inclineStanding\"] = inclineStanding\n",
    "        df_slice[\"inclineSitting\"] = inclineSitting\n",
    "        df_slice[\"inclineLying\"] = inclineLying\n",
    "\n",
    "        x_list_test.append(df_slice)\n",
    "\n",
    "        test_labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5049650",
   "metadata": {},
   "source": [
    "## Feature computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_statistical_measures_gl_acc(x_list):\n",
    "    X_train = pd.DataFrame()\n",
    "\n",
    "    for df_temp in x_list:\n",
    "        \n",
    "        id_p = df_temp.loc[1,'id']\n",
    "        phase = df_temp.loc[1,'phase']\n",
    "        time_median = df_temp.loc[1,'Time']\n",
    "        \n",
    "        cgm_summary = list(cgm.summary(df_temp))\n",
    "        cgm_J_index = cgm.J_index(df_temp)\n",
    "\n",
    "        cgm_interdaycv = cgm.interdaycv(df_temp)\n",
    "\n",
    "        cgm_summary.append(cgm_J_index)\n",
    "        cgm_summary.append(cgm_interdaycv)\n",
    "\n",
    "        \n",
    "        \n",
    "        # mean\n",
    "        z_mean = df_temp[\"axis3\"].mean()\n",
    "\n",
    "        # max\n",
    "        y_max = df_temp[\"axis2\"].max()\n",
    "\n",
    "\n",
    "        # energy\n",
    "        z_energy = ((df_temp[\"axis3\"] **2) / 100).sum()\n",
    "        \n",
    "        general = []\n",
    "        general.extend([id_p, phase, time_median])\n",
    "\n",
    "\n",
    "        acc_summary = []\n",
    "        acc_summary.extend([z_mean, y_max ,z_energy])\n",
    "        \n",
    "\n",
    "        features = general\n",
    "        features.extend(cgm_summary)\n",
    "        features.extend(acc_summary)\n",
    "\n",
    "        X_train_temp = pd.DataFrame([features], columns = [\"id\", \"phase\",\"time\",\"mean\", \"median\",\"minimum\", \"maximum\",\"first_quartile\", \"third_quartile\",\n",
    "                                                              \"J_index\",\"cgm_interdaycv\", \n",
    "                                                              \"z_mean\", \"y_max\", \"z_energy\"])\n",
    "\n",
    "        \n",
    "        X_train = pd.concat([X_train, X_train_temp], ignore_index=True)\n",
    "        \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95859e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_statistical_measures_gl_tsc(x_list):\n",
    "    X_train = pd.DataFrame()\n",
    "\n",
    "    for df_temp in x_list:\n",
    "        time_median = df_temp.loc[1,'Time']\n",
    "        cgm_summary = list(cgm.summary(df_temp))\n",
    "        cgm_LBGI = cgm.LBGI(df_temp)\n",
    "        cgm_HBGI = cgm.HBGI(df_temp)\n",
    "        cgm_ADRR = cgm.ADRR(df_temp)\n",
    "        cgm_GMI = cgm.GMI(df_temp)\n",
    "        cgm_J_index = cgm.J_index(df_temp)\n",
    "        cgm_eA1c = cgm.eA1c(df_temp)\n",
    "        cgm_interdaysd = cgm.interdaysd(df_temp)\n",
    "        cgm_interdaycv = cgm.interdaycv(df_temp)\n",
    "\n",
    "        cgm_summary.append(cgm_LBGI)\n",
    "        cgm_summary.append(cgm_HBGI)\n",
    "        cgm_summary.append(cgm_ADRR)\n",
    "        cgm_summary.append(cgm_GMI)\n",
    "        cgm_summary.append(cgm_J_index)\n",
    "        cgm_summary.append(cgm_eA1c)\n",
    "        cgm_summary.append(cgm_interdaysd)\n",
    "        cgm_summary.append(cgm_interdaycv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        general = []\n",
    "        general.extend([time_median])\n",
    "        general.extend(cgm_summary)\n",
    "\n",
    "        X_train_temp = pd.DataFrame([general],\n",
    "                                    columns=[\"time\",\"mean\", \"median\", \"minimum\", \"maximum\", \"first_quartile\", \"third_quartile\",\n",
    "                                             \"LBGI\", \"HBGI\", \"ADRR\", \"GMI\", \"J_index\", \"eA1c\", \"interdaysd\",\n",
    "                                             \"cgm_interdaycv\"])\n",
    "\n",
    "        X_train = pd.concat([X_train, X_train_temp], ignore_index=True)\n",
    "        \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feat_statistical_measures_acc_tsc(x_list):\n",
    "    X_train = pd.DataFrame()\n",
    "\n",
    "    for df_temp in x_list:\n",
    "        time_median = df_temp.loc[1,'Time']\n",
    "\n",
    "        # mean\n",
    "        z_mean = df_temp[\"axis3\"].mean()\n",
    "\n",
    "        # max\n",
    "        y_max = df_temp[\"axis2\"].max()\n",
    "\n",
    "\n",
    "        # energy\n",
    "        z_energy = ((df_temp[\"axis3\"] **2) / 100).sum()\n",
    "\n",
    "        general = []\n",
    "        general.extend([time_median])\n",
    "\n",
    "        acc_summary = []\n",
    "        acc_summary.extend([z_mean, y_max ,z_energy])\n",
    "        \n",
    "        features = general\n",
    "        features.extend(acc_summary)\n",
    "\n",
    "        X_train_temp = pd.DataFrame([features],\n",
    "                                    columns=[\"time\",\"z_mean\", \"y_max\", \"z_energy\"])\n",
    "\n",
    "        X_train = pd.concat([X_train, X_train_temp], ignore_index=True)\n",
    "\n",
    "    return X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = feat_statistical_measures_gl_acc(x_list_test)\n",
    "\n",
    "X_train = feat_statistical_measures_gl_acc(x_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = feat_statistical_measures_gl_tsc(x_list_test)\n",
    "\n",
    "X_train = feat_statistical_measures_gl_tsc(x_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d279127",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6082e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = feat_statistical_measures_acc_tsc(x_list_test)\n",
    "\n",
    "X_train = feat_statistical_measures_acc_tsc(x_list_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5a293",
   "metadata": {},
   "source": [
    "## Saving and Loading the featured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd0b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583af845",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"TSC_data/eval_Xtest.csv\", sep='\\t')\n",
    "X_train.to_csv(\"TSC_data/eval_Xrain.csv\", sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_float = y_train\n",
    "y_test_float = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692dab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('TSC_data/eval_y_train.npy', y_train_float)\n",
    "np.save('TSC_data/eval_y_test.npy', y_test_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('eval_Xtest.csv', sep='\\t')\n",
    "X_train = pd.read_csv('eval_Xrain.csv', sep='\\t')\n",
    "\n",
    "X_test = X_test.drop([\"Unnamed: 0\"], axis=1)\n",
    "X_train = X_train.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c2f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_float = np.load('TSC_data\\\\eval_y_train.npy')\n",
    "y_test_float = np.load('TSC_data\\\\eval_y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7676e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list(set(y_train_float))\n",
    "mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a559255",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257dc0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe = X_train.drop([\"time\"], axis=1)\n",
    "X_test_rfe = X_test.drop([\"time\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# fit random forest model\n",
    "model = RandomForestRegressor(n_estimators=500, random_state=1)\n",
    "model.fit(X_train_rfe, y_train_float)\n",
    "# show importance scores\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e03938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfe = RFE(RandomForestRegressor(n_estimators=500, random_state=1), n_features_to_select=4)\n",
    "fit = rfe.fit(X_train_rfe, y_train_float)\n",
    "# report selected features\n",
    "print('Selected Features:')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ed54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(fit.support_)):\n",
    "    if fit.support_[i]:\n",
    "        print(names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1709e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = X_train_rfe.columns.values[0:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd59f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "X, y = make_friedman1(n_samples=50, n_features=5, random_state=0)\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "selector = RFE(estimator, n_features_to_select=5, step=1)\n",
    "selector = selector.fit(X_train_rfe, y_train_float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_to_select = 10\n",
    "rfe = RFE(regressor, n_features_to_select=n_features_to_select)\n",
    "rfe.fit(X_train_rfe, y_train_float)\n",
    "predictions_rfe = rfe.predict(X_test_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3397d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions_rfe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "features = X_train.columns.to_list()\n",
    "for x, y in (sorted(zip(selector.ranking_ , features), key=itemgetter(0))):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c8f1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444bddd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0775fefa",
   "metadata": {},
   "source": [
    "## Building the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ca86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list(set(y_test_float))\n",
    "\n",
    "mylist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf543d9",
   "metadata": {},
   "source": [
    "### Test-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a4917",
   "metadata": {},
   "source": [
    "### acc and gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d6b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "X_test.time = pd.to_datetime(X_test.time)\n",
    "\n",
    "x_list_test_tsc_1st = []\n",
    "test_labels_tsc = []\n",
    "x_list_test_tsc_2nd = []\n",
    "counter=0\n",
    "\n",
    "\n",
    "last_time_before = X_test['time'].values[0]\n",
    "\n",
    "for i in range(0, X_test.shape[0], 1):\n",
    "    time = X_test['time'].values[i]\n",
    "    cgm_interdaycv =  X_test['cgm_interdaycv'].values[i]\n",
    "    J_index = X_test['J_index'].values[i]\n",
    "    maximum = X_test['maximum'].values[i]\n",
    "    z_mean = X_test['z_mean'].values[i]\n",
    "    y_max = X_test['y_max'].values[i]\n",
    "    z_energy = X_test['z_energy'].values[i]\n",
    "    \n",
    "    timedelta_first =  time - last_time_before\n",
    "\n",
    "    one_hour = 3600000000000\n",
    "    \n",
    "    if timedelta_first < one_hour and counter < 5:\n",
    "        x_list_test_tsc_3rd = []\n",
    "        x_list_test_tsc_3rd.append(cgm_interdaycv)\n",
    "        x_list_test_tsc_3rd.append(J_index)\n",
    "        x_list_test_tsc_3rd.append(maximum)\n",
    "        x_list_test_tsc_3rd.append(z_mean)\n",
    "        x_list_test_tsc_3rd.append(y_max)\n",
    "        x_list_test_tsc_3rd.append(z_energy)\n",
    "        x_list_test_tsc_2nd.append(x_list_test_tsc_3rd)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        if counter == 5:\n",
    "            x_list_test_tsc_1st.append(x_list_test_tsc_2nd)\n",
    "            test_labels_tsc.append(y_test_float[i])\n",
    "            \n",
    "        counter = 0\n",
    "        x_list_test_tsc_2nd = [] \n",
    "        x_list_test_tsc_3rd = []\n",
    "        x_list_test_tsc_3rd.append(cgm_interdaycv)\n",
    "        x_list_test_tsc_3rd.append(J_index)\n",
    "        x_list_test_tsc_3rd.append(maximum)\n",
    "        x_list_test_tsc_3rd.append(z_mean)\n",
    "        x_list_test_tsc_3rd.append(y_max)\n",
    "        x_list_test_tsc_3rd.append(z_energy)\n",
    "        x_list_test_tsc_2nd.append(x_list_test_tsc_3rd)\n",
    "        \n",
    "    counter += 1\n",
    "    \n",
    "    last_time_before = time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcd6420",
   "metadata": {},
   "source": [
    "### gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "X_test.time = pd.to_datetime(X_test.time)\n",
    "\n",
    "x_list_test_tsc_1st = []\n",
    "test_labels_tsc = []\n",
    "x_list_test_tsc_2nd = []\n",
    "counter=0\n",
    "\n",
    "\n",
    "last_time_before = X_test['time'].values[0]\n",
    "\n",
    "for i in range(0, X_test.shape[0], 1):\n",
    "    time = X_test['time'].values[i]\n",
    "    cgm_interdaycv =  X_test['cgm_interdaycv'].values[i]\n",
    "    J_index = X_test['J_index'].values[i]\n",
    "    maximum = X_test['maximum'].values[i]\n",
    "    \n",
    "    timedelta_first =  time - last_time_before\n",
    "\n",
    "    one_hour = 3600000000000\n",
    "    \n",
    "    if timedelta_first < one_hour and counter < 5:\n",
    "        x_list_test_tsc_3rd = []\n",
    "        x_list_test_tsc_3rd.append(cgm_interdaycv)\n",
    "        x_list_test_tsc_3rd.append(J_index)\n",
    "        x_list_test_tsc_3rd.append(maximum)\n",
    "\n",
    "        x_list_test_tsc_2nd.append(x_list_test_tsc_3rd)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        if counter == 5:\n",
    "            x_list_test_tsc_1st.append(x_list_test_tsc_2nd)\n",
    "            test_labels_tsc.append(y_test_float[i])\n",
    "            \n",
    "        counter = 0\n",
    "        x_list_test_tsc_2nd = [] \n",
    "        x_list_test_tsc_3rd = []\n",
    "        x_list_test_tsc_3rd.append(cgm_interdaycv)\n",
    "        x_list_test_tsc_3rd.append(J_index)\n",
    "        x_list_test_tsc_3rd.append(maximum)\n",
    "        x_list_test_tsc_2nd.append(x_list_test_tsc_3rd)\n",
    "        \n",
    "    counter += 1\n",
    "    \n",
    "    last_time_before = time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ce506",
   "metadata": {},
   "source": [
    "### acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5202a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "X_test.time = pd.to_datetime(X_test.time)\n",
    "\n",
    "x_list_test_tsc_1st = []\n",
    "test_labels_tsc = []\n",
    "x_list_test_tsc_2nd = []\n",
    "counter=0\n",
    "\n",
    "\n",
    "last_time_before = X_test['time'].values[0]\n",
    "\n",
    "for i in range(0, X_test.shape[0], 1):\n",
    "    time = X_test['time'].values[i]\n",
    "    z_mean = X_test['z_mean'].values[i]\n",
    "    y_max = X_test['y_max'].values[i]\n",
    "    z_energy = X_test['z_energy'].values[i]\n",
    "    \n",
    "    timedelta_first =  time - last_time_before\n",
    "\n",
    "    one_hour = 3600000000000\n",
    "    \n",
    "    if timedelta_first < one_hour and counter < 5:\n",
    "        x_list_test_tsc_3rd = []\n",
    "\n",
    "        x_list_test_tsc_3rd.append(z_mean)\n",
    "        x_list_test_tsc_3rd.append(y_max)\n",
    "        x_list_test_tsc_3rd.append(z_energy)\n",
    "        x_list_test_tsc_2nd.append(x_list_test_tsc_3rd)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        if counter == 5:\n",
    "            x_list_test_tsc_1st.append(x_list_test_tsc_2nd)\n",
    "            test_labels_tsc.append(y_test_float[i])\n",
    "            \n",
    "        counter = 0\n",
    "        x_list_test_tsc_2nd = [] \n",
    "        x_list_test_tsc_3rd = []\n",
    "\n",
    "        x_list_test_tsc_3rd.append(z_mean)\n",
    "        x_list_test_tsc_3rd.append(y_max)\n",
    "        x_list_test_tsc_3rd.append(z_energy)\n",
    "        x_list_test_tsc_2nd.append(x_list_test_tsc_3rd)\n",
    "        \n",
    "    counter += 1\n",
    "    \n",
    "    last_time_before = time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed9ac1b",
   "metadata": {},
   "source": [
    "### Train-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "X_train.time = pd.to_datetime(X_train.time)\n",
    "\n",
    "\n",
    "x_list_train_tsc_1st = []\n",
    "train_labels_tsc = []\n",
    "x_list_train_tsc_2nd = []\n",
    "counter = 0\n",
    "\n",
    "\n",
    "last_time_before = X_train['time'].values[0]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, X_train.shape[0], 1):\n",
    "    time = X_train['time'].values[i]\n",
    "    cgm_interdaycv =  X_train['cgm_interdaycv'].values[i]\n",
    "#     steps =  X_train['steps'].values[i]\n",
    "#     interdaysd =  X_train['interdaysd'].values[i]\n",
    "#     cgm_MAGE =  X_train['cgm_MAGE'].values[i]\n",
    "    J_index = X_train['J_index'].values[i]\n",
    "    maximum = X_train['maximum'].values[i]\n",
    "    z_mean = X_train['z_mean'].values[i]\n",
    "    y_max = X_train['y_max'].values[i]\n",
    "    z_energy = X_train['z_energy'].values[i]\n",
    "    \n",
    "    timedelta_first =  time - last_time_before\n",
    "\n",
    "    one_hour = 3600000000000\n",
    "    \n",
    "    if timedelta_first < one_hour and counter < 5:\n",
    "        \n",
    "        x_list_train_tsc_3rd = []\n",
    "        x_list_train_tsc_3rd.append(cgm_interdaycv)\n",
    "        x_list_train_tsc_3rd.append(J_index)\n",
    "        x_list_train_tsc_3rd.append(maximum)\n",
    "        x_list_train_tsc_3rd.append(z_mean)\n",
    "        x_list_train_tsc_3rd.append(y_max)\n",
    "        x_list_train_tsc_3rd.append(z_energy)\n",
    "        x_list_train_tsc_2nd.append(x_list_train_tsc_3rd)\n",
    "    \n",
    "    else:\n",
    "        if counter == 5:\n",
    "            x_list_train_tsc_1st.append(x_list_train_tsc_2nd)\n",
    "            train_labels_tsc.append(y_train_float[i])\n",
    "            \n",
    "        counter = 0\n",
    "        x_list_train_tsc_2nd = [] \n",
    "        x_list_train_tsc_3rd = []\n",
    "        x_list_train_tsc_3rd.append(cgm_interdaycv)\n",
    "        x_list_train_tsc_3rd.append(J_index)\n",
    "        x_list_train_tsc_3rd.append(maximum)\n",
    "        x_list_train_tsc_3rd.append(z_mean)\n",
    "        x_list_train_tsc_3rd.append(y_max)\n",
    "        x_list_train_tsc_3rd.append(z_energy)\n",
    "        x_list_train_tsc_2nd.append(x_list_train_tsc_3rd)\n",
    "    counter += 1\n",
    "    last_time_before = time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d20645",
   "metadata": {},
   "source": [
    "### gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "X_train.time = pd.to_datetime(X_train.time)\n",
    "\n",
    "\n",
    "x_list_train_tsc_1st = []\n",
    "train_labels_tsc = []\n",
    "x_list_train_tsc_2nd = []\n",
    "counter = 0\n",
    "\n",
    "\n",
    "last_time_before = X_train['time'].values[0]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, X_train.shape[0], 1):\n",
    "    time = X_train['time'].values[i]\n",
    "    cgm_interdaycv =  X_train['cgm_interdaycv'].values[i]\n",
    "    J_index = X_train['J_index'].values[i]\n",
    "    maximum = X_train['maximum'].values[i]\n",
    "    \n",
    "    timedelta_first =  time - last_time_before\n",
    "\n",
    "    one_hour = 3600000000000\n",
    "    \n",
    "    if timedelta_first < one_hour and counter < 5:\n",
    "        \n",
    "        x_list_train_tsc_3rd = []\n",
    "        x_list_train_tsc_3rd.append(cgm_interdaycv)\n",
    "        x_list_train_tsc_3rd.append(J_index)\n",
    "        x_list_train_tsc_3rd.append(maximum)\n",
    "\n",
    "        x_list_train_tsc_2nd.append(x_list_train_tsc_3rd)\n",
    "    \n",
    "    else:\n",
    "        if counter == 5:\n",
    "            x_list_train_tsc_1st.append(x_list_train_tsc_2nd)\n",
    "            train_labels_tsc.append(y_train_float[i])\n",
    "            \n",
    "        counter = 0\n",
    "        x_list_train_tsc_2nd = [] \n",
    "        x_list_train_tsc_3rd = []\n",
    "        x_list_train_tsc_3rd.append(cgm_interdaycv)\n",
    "        x_list_train_tsc_3rd.append(J_index)\n",
    "        x_list_train_tsc_3rd.append(maximum)\n",
    "\n",
    "        x_list_train_tsc_2nd.append(x_list_train_tsc_3rd)\n",
    "    counter += 1\n",
    "    last_time_before = time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260c23a",
   "metadata": {},
   "source": [
    "### acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc12e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "X_train.time = pd.to_datetime(X_train.time)\n",
    "\n",
    "\n",
    "x_list_train_tsc_1st = []\n",
    "train_labels_tsc = []\n",
    "x_list_train_tsc_2nd = []\n",
    "counter = 0\n",
    "\n",
    "\n",
    "last_time_before = X_train['time'].values[0]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, X_train.shape[0], 1):\n",
    "    time = X_train['time'].values[i]\n",
    "    z_mean = X_train['z_mean'].values[i]\n",
    "    y_max = X_train['y_max'].values[i]\n",
    "    z_energy = X_train['z_energy'].values[i]\n",
    "    \n",
    "    timedelta_first =  time - last_time_before\n",
    "\n",
    "    one_hour = 3600000000000\n",
    "    \n",
    "    if timedelta_first < one_hour and counter < 5:\n",
    "        \n",
    "        x_list_train_tsc_3rd = []\n",
    "        x_list_train_tsc_3rd.append(z_mean)\n",
    "        x_list_train_tsc_3rd.append(y_max)\n",
    "        x_list_train_tsc_3rd.append(z_energy)\n",
    "        x_list_train_tsc_2nd.append(x_list_train_tsc_3rd)\n",
    "    \n",
    "    else:\n",
    "        if counter == 5:\n",
    "            x_list_train_tsc_1st.append(x_list_train_tsc_2nd)\n",
    "            train_labels_tsc.append(y_train_float[i])\n",
    "            \n",
    "        counter = 0\n",
    "        x_list_train_tsc_2nd = [] \n",
    "        x_list_train_tsc_3rd = []\n",
    "        x_list_train_tsc_3rd.append(z_mean)\n",
    "        x_list_train_tsc_3rd.append(y_max)\n",
    "        x_list_train_tsc_3rd.append(z_energy)\n",
    "        x_list_train_tsc_2nd.append(x_list_train_tsc_3rd)\n",
    "    counter += 1\n",
    "    last_time_before = time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b829f8",
   "metadata": {},
   "source": [
    "# TS Learn Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ae5d5",
   "metadata": {},
   "source": [
    "### To Time Series Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c065a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
    "from tslearn import generators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41418cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =to_time_series_dataset(x_list_train_tsc_1st)\n",
    "X_test =to_time_series_dataset(x_list_test_tsc_1st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6483c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train =  np.array(train_labels_tsc)\n",
    "y_test =  np.array(test_labels_tsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5496386",
   "metadata": {},
   "source": [
    "### Checking for Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_test).keys()) \n",
    "print(Counter(y_test).values())\n",
    "print(Counter(y_train).keys())\n",
    "print(Counter(y_train).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31271be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2d_test = X_test.reshape(X_test.shape[0], -1)\n",
    "data2d_train = X_train.reshape(X_train.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399194ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(data2d_test.shape)\n",
    "print(data2d_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d291f890",
   "metadata": {},
   "source": [
    "### Undersampling with Random Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582ee9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import collections\n",
    "rus = RandomUnderSampler(random_state=0, replacement=True)\n",
    "data2d_test_resampled , y_test_resampled = rus.fit_resample(data2d_test, y_test)\n",
    "data2d_train_resampled , y_train_resampled = rus.fit_resample(data2d_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c93898",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data2d_test_resampled.shape)\n",
    "print(data2d_train_resampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5404f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_test_resampled).keys())\n",
    "print(Counter(y_test_resampled).values()) \n",
    "print(Counter(y_train_resampled).keys()) \n",
    "print(Counter(y_train_resampled).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326cf507",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2d_test_resampled.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd93d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3d_X_test = data2d_test_resampled.reshape(-1, X_test.shape[1], X_test.shape[2])\n",
    "data3d_X_train = data2d_train_resampled.reshape(-1, X_train.shape[1], X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786122bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data3d_X_test.shape)\n",
    "print(data3d_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc7295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch_table_plot(grid_clf, param_name,\n",
    "                          num_results=15,\n",
    "                          negative=True,\n",
    "                          graph=True,\n",
    "                          display_all_params=True):\n",
    "\n",
    "    '''Display grid search results\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "\n",
    "    grid_clf           the estimator resulting from a grid search\n",
    "                       for example: grid_clf = GridSearchCV( ...\n",
    "\n",
    "    param_name         a string with the name of the parameter being tested\n",
    "\n",
    "    num_results        an integer indicating the number of results to display\n",
    "                       Default: 15\n",
    "\n",
    "    negative           boolean: should the sign of the score be reversed?\n",
    "                       scoring = 'neg_log_loss', for instance\n",
    "                       Default: True\n",
    "\n",
    "    graph              boolean: should a graph be produced?\n",
    "                       non-numeric parameters (True/False, None) don't graph well\n",
    "                       Default: True\n",
    "\n",
    "    display_all_params boolean: should we print out all of the parameters, not just the ones searched for?\n",
    "                       Default: True\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "\n",
    "    GridSearch_table_plot(grid_clf, \"min_samples_leaf\")\n",
    "\n",
    "                          '''\n",
    "    from matplotlib      import pyplot as plt\n",
    "    from IPython.display import display\n",
    "    import pandas as pd\n",
    "\n",
    "    clf = grid_clf.best_estimator_\n",
    "    clf_params = grid_clf.best_params_\n",
    "    if negative:\n",
    "        clf_score = -grid_clf.best_score_\n",
    "    else:\n",
    "        clf_score = grid_clf.best_score_\n",
    "    clf_stdev = grid_clf.cv_results_['std_test_score'][grid_clf.best_index_]\n",
    "    cv_results = grid_clf.cv_results_\n",
    "\n",
    "    print(\"best parameters: {}\".format(clf_params))\n",
    "    print(\"best score:      {:0.5f} (+/-{:0.5f})\".format(clf_score, clf_stdev))\n",
    "    if display_all_params:\n",
    "        import pprint\n",
    "        pprint.pprint(clf.get_params())\n",
    "\n",
    "    # pick out the best results\n",
    "    # =========================\n",
    "    scores_df = pd.DataFrame(cv_results).sort_values(by='rank_test_score')\n",
    "\n",
    "    best_row = scores_df.iloc[0, :]\n",
    "    if negative:\n",
    "        best_mean = -best_row['mean_test_score']\n",
    "    else:\n",
    "        best_mean = best_row['mean_test_score']\n",
    "    best_stdev = best_row['std_test_score']\n",
    "    best_param = best_row['param_' + param_name]\n",
    "\n",
    "    # display the top 'num_results' results\n",
    "    # =====================================\n",
    "    display(pd.DataFrame(cv_results) \\\n",
    "            .sort_values(by='rank_test_score').head(num_results))\n",
    "\n",
    "    # plot the results\n",
    "    # ================\n",
    "    scores_df = scores_df.sort_values(by='param_' + param_name)\n",
    "\n",
    "    if negative:\n",
    "        means = -scores_df['mean_test_score']\n",
    "    else:\n",
    "        means = scores_df['mean_test_score']\n",
    "    stds = scores_df['std_test_score']\n",
    "    params = scores_df['param_' + param_name]\n",
    "\n",
    "    # plot\n",
    "    if graph:\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.errorbar(params, means, yerr=stds)\n",
    "\n",
    "        plt.axhline(y=best_mean + best_stdev, color='red')\n",
    "        plt.axhline(y=best_mean - best_stdev, color='red')\n",
    "        plt.plot(best_param, best_mean, 'or')\n",
    "\n",
    "        plt.title(param_name + \" vs Score\\nBest Score {:0.5f}\".format(clf_score))\n",
    "        plt.xlabel(param_name)\n",
    "        plt.ylabel('Score')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2642b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d622f05f",
   "metadata": {},
   "source": [
    "## KNeighborsTimeSeriesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "start = \"path_models_TSC\\\\\"\n",
    "end = \".pkl\"\n",
    "folder = \"gl\\\\\"\n",
    "ml_type = \"KNN_TSC\"\n",
    "\n",
    "path = start + folder + ml_type + end\n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a31dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier\n",
    "knn = KNeighborsTimeSeriesClassifier(n_neighbors=2)\n",
    "knn.fit(data3d_X_train, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set search parameters\n",
    "n_neighbors = [int(x) for x in np.linspace(start = 1, stop = 100, num = 50)]   \n",
    "weights = ['uniform','distance']\n",
    "metric = ['euclidean','manhattan','chebyshev','minkowski'] \n",
    "random_grid = {\n",
    "    'n_neighbors': n_neighbors,\n",
    "    'weights': weights,\n",
    "    'metric': metric,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efabad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_random = RandomizedSearchCV(estimator = knn, random_state = 42,n_jobs = -1,param_distributions = random_grid,n_iter = 20, cv=3,verbose = 2)\n",
    "knn_random.fit(data3d_X_train, y_train_resampled)\n",
    "knn_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc405961",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_random.best_params_\n",
    "\n",
    "best_estimator = knn_random.best_estimator_\n",
    "\n",
    "best_estimator.fit(data3d_X_train, y_train_resampled)\n",
    "\n",
    "pred = best_estimator.predict(data3d_X_test)\n",
    "\n",
    "accuracy_score(y_test_resampled, pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(data3d_X_test)\n",
    "\n",
    "accuracy_score(pred, y_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_resampled, smoothing(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce76da",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch_table_plot(knn_random, \"weights\", negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47a0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(data3d_X_test)\n",
    "accuracy_score(y_test_resampled, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb322dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_resampled, smoothing(y_pred))\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833583f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled, smoothing(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0eaa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('TSC_data/models_TSC/acc/KNN_TSC.pkl','wb') as f:\n",
    "    pickle.dump(knn,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f438391",
   "metadata": {},
   "source": [
    "## TimeSeriesSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.svm import TimeSeriesSVC\n",
    "clf = TimeSeriesSVC(C=1.0, kernel=\"gak\", gamma=0.001)\n",
    "clf.fit(data3d_X_train,y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(data3d_X_test)\n",
    "accuracy_score(y_test_resampled, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3624d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel': ['rbf', 'sigmoid'],\n",
    "             'C': [1.0, 100.0, 1000.0],\n",
    "             'gamma': [0.001, 0.01,0.1]}#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b22c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_estimator = RandomizedSearchCV(estimator = clf,\n",
    "                                   param_distributions = parameters,\n",
    "                                   cv = 5,\n",
    "                                   n_iter = 10,\n",
    "                                   scoring = 'accuracy',\n",
    "                                   n_jobs = -1,\n",
    "                                   verbose = 1, \n",
    "                                   random_state = 1,\n",
    "                                  )\n",
    "\n",
    "random_estimator.fit(data3d_X_train, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_estimator.best_params_\n",
    "\n",
    "best_estimator = random_estimator.best_estimator_\n",
    "\n",
    "best_estimator.fit(data3d_X_train, y_train_resampled)\n",
    "\n",
    "pred = best_estimator.predict(data3d_X_test)\n",
    "\n",
    "accuracy_score(pred, y_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a4f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch_table_plot(random_estimator, \"gamma\", negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb1215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test_resampled, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ba291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_resampled, smoothing(y_pred))\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('TSC_data/models_TSC/both/CLF_TSC.pkl','wb') as f:\n",
    "    pickle.dump(clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0677b4",
   "metadata": {},
   "source": [
    "## Clustering TimeSeriesKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ddef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "km = TimeSeriesKMeans(n_clusters=2, metric=\"dtw\")\n",
    "labels = km.fit_predict(data3d_X_train)\n",
    "\n",
    "\n",
    "km_bis = TimeSeriesKMeans(n_clusters=2, metric=\"softdtw\")\n",
    "labels_bis = km_bis.fit_predict(data3d_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f13151",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\"actual\":y_train_resampled, \"prediction\":labels})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
