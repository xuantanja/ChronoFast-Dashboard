{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79bd88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cgmquantify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086cdcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad01e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cgmquantify as cgm\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "from datetime import date\n",
    "from scipy.stats import stats\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366c662",
   "metadata": {},
   "source": [
    "## Read dataframe with labeled by patient_reported_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcd1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_all = pd.read_csv('df_overnight_and_PRO.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a658f60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged_all.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec341cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_all = df_merged_all.dropna(subset=['axis1', 'axis2', 'axis3'],how='all')\n",
    "\n",
    "df_merged_all['axis1'] = df_merged_all['axis1'].fillna(0)\n",
    "df_merged_all['axis2'] = df_merged_all['axis2'].fillna(0)\n",
    "df_merged_all['axis3'] = df_merged_all['axis3'].fillna(0)\n",
    "\n",
    "df_merged_all['time'] = pd.to_datetime(df_merged_all['time'] ,errors = 'coerce')\n",
    "\n",
    "df_merged_all = df_merged_all.reset_index(drop=True)\n",
    "df_merged_all = df_merged_all.drop([\"Unnamed: 0\", \"joinID\"], axis=1)\n",
    "\n",
    "fasting_states_to_keep = ['fasting', 'non-fasting']\n",
    "df_merged_all = df_merged_all[df_merged_all.label.isin(fasting_states_to_keep)]\n",
    "\n",
    "\n",
    "final_df = df_merged_all.sort_values(by=['id', 'time'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a72e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Time'] = pd.to_datetime(final_df['time'], format='%Y-%m-%dT%H:%M:%S')\n",
    "final_df['Glucose'] = pd.to_numeric(final_df['gl'])\n",
    "final_df['Day'] = final_df[\"Time\"].dt.date\n",
    "final_df = final_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff88f5",
   "metadata": {},
   "source": [
    "## Split to windowed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list_train = []\n",
    "train_labels = []\n",
    "\n",
    "\n",
    "window_size = 3\n",
    "step_size = 1\n",
    "\n",
    "# creating overlaping windows of size window-size 100\n",
    "for i in range(0, df_train.shape[0] - window_size, step_size):\n",
    "    time = df_train['Time'].values[i: i + window_size]\n",
    "    times = df_train['Day'].values[i: i + window_size]\n",
    "    gls = df_train['Glucose'].values[i: i + window_size]\n",
    "    steps = df_train['steps'].values[i: i + window_size]\n",
    "    inclineStanding = df_train['inclineStanding'].values[i: i + window_size]\n",
    "    inclineSitting = df_train['inclineSitting'].values[i: i + window_size]\n",
    "    inclineLying = df_train['inclineLying'].values[i: i + window_size]\n",
    "    \n",
    "    timedelta_first = time[1] - time[0]\n",
    "    timedelta_second = time[2] - time[1]\n",
    "    one_hour = 3600000000000\n",
    "    \n",
    "    if (timedelta_first < one_hour and timedelta_second < one_hour):\n",
    "   \n",
    "    \n",
    "        xs = df_train['axis1'].values[i: i + window_size]\n",
    "        ys = df_train['axis2'].values[i: i + window_size]\n",
    "        zs = df_train['axis3'].values[i: i + window_size]\n",
    "\n",
    "        label = stats.mode(df_train['label'][i: i + window_size])[0][0]\n",
    "\n",
    "        df_slice = pd.DataFrame(time, columns=['Time'])\n",
    "        df_slice[\"Day\"] = times\n",
    "        df_slice[\"Glucose\"] = gls   \n",
    "        df_slice[\"axis1\"] = xs\n",
    "        df_slice[\"axis2\"] = ys\n",
    "        df_slice[\"axis3\"] = zs\n",
    "        df_slice[\"steps\"] = steps\n",
    "        df_slice[\"inclineStanding\"] = inclineStanding\n",
    "        df_slice[\"inclineSitting\"] = inclineSitting\n",
    "        df_slice[\"inclineLying\"] = inclineLying\n",
    "\n",
    "        x_list_train.append(df_slice)\n",
    "\n",
    "        train_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce688881",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list_test = []\n",
    "test_labels = []\n",
    "\n",
    "\n",
    "window_size = 3\n",
    "step_size = 1\n",
    "\n",
    "# creating overlaping windows of size window-size 100\n",
    "for i in range(0, df_test.shape[0] - window_size, step_size):\n",
    "    time = df_test['Time'].values[i: i + window_size]\n",
    "    times = df_test['Day'].values[i: i + window_size]\n",
    "    gls = df_test['Glucose'].values[i: i + window_size]\n",
    "    steps = df_test['steps'].values[i: i + window_size]\n",
    "    inclineStanding = df_test['inclineStanding'].values[i: i + window_size]\n",
    "    inclineSitting = df_test['inclineSitting'].values[i: i + window_size]\n",
    "    inclineLying = df_test['inclineLying'].values[i: i + window_size]\n",
    "    \n",
    "    timedelta_first = time[1] - time[0]\n",
    "    timedelta_second = time[2] - time[1]\n",
    "    one_hour = 3600000000000\n",
    "    \n",
    "    if (timedelta_first < one_hour and timedelta_second < one_hour):\n",
    "    \n",
    "        xs = df_test['axis1'].values[i: i + window_size]\n",
    "        ys = df_test['axis2'].values[i: i + window_size]\n",
    "        zs = df_test['axis3'].values[i: i + window_size]\n",
    "\n",
    "        label = stats.mode(df_test['label'][i: i + window_size])[0][0]\n",
    "\n",
    "        df_slice = pd.DataFrame(time, columns=['Time'])\n",
    "        df_slice[\"Day\"] = times\n",
    "        df_slice[\"Glucose\"] = gls     \n",
    "        df_slice[\"axis1\"] = xs\n",
    "        df_slice[\"axis2\"] = ys\n",
    "        df_slice[\"axis3\"] = zs\n",
    "        df_slice[\"steps\"] = steps\n",
    "        df_slice[\"inclineStanding\"] = inclineStanding\n",
    "        df_slice[\"inclineSitting\"] = inclineSitting\n",
    "        df_slice[\"inclineLying\"] = inclineLying\n",
    "\n",
    "        x_list_test.append(df_slice)\n",
    "\n",
    "        test_labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca07ec8",
   "metadata": {},
   "source": [
    "## Feature computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_statistical_measures_gl_acc(x_list):\n",
    "    X_train = pd.DataFrame()\n",
    "\n",
    "    for df_temp in x_list:\n",
    "        cgm_summary = list(cgm.summary(df_temp))\n",
    "        cgm_LBGI = cgm.LBGI(df_temp)\n",
    "        cgm_HBGI = cgm.HBGI(df_temp)\n",
    "        cgm_ADRR = cgm.ADRR(df_temp)\n",
    "        cgm_GMI = cgm.GMI(df_temp)\n",
    "        cgm_J_index = cgm.J_index(df_temp)\n",
    "        cgm_eA1c = cgm.eA1c(df_temp)\n",
    "        cgm_interdaysd = cgm.interdaysd(df_temp)\n",
    "        cgm_interdaycv = cgm.interdaycv(df_temp)\n",
    "        cgm_TOR = cgm.TOR(df_temp, sd=1, sr=15)\n",
    "        cgm_TIR = cgm.TIR(df_temp, sd=1, sr=15)\n",
    "        cgm_POR = cgm.POR(df_temp, sd=1, sr=15)\n",
    "        cgm_MAGN = cgm.MAGN(df_temp, sd=1)\n",
    "        cgm_MAGE = cgm.MAGE(df_temp, sd=1)  \n",
    "        \n",
    "        cgm_summary.append(cgm_LBGI)\n",
    "        cgm_summary.append(cgm_HBGI)\n",
    "        cgm_summary.append(cgm_ADRR)\n",
    "        cgm_summary.append(cgm_GMI)\n",
    "        cgm_summary.append(cgm_J_index)\n",
    "        cgm_summary.append(cgm_eA1c)\n",
    "        cgm_summary.append(cgm_interdaysd)\n",
    "        cgm_summary.append(cgm_interdaycv)\n",
    "\n",
    "        cgm_summary.append(cgm_TOR)\n",
    "        cgm_summary.append(cgm_TIR)\n",
    "        cgm_summary.append(cgm_POR)\n",
    "        \n",
    "        \n",
    "        # mean\n",
    "        x_mean = df_temp[\"axis1\"].mean()\n",
    "        y_mean = df_temp[\"axis2\"].mean()\n",
    "        z_mean = df_temp[\"axis3\"].mean()\n",
    "\n",
    "        # std dev\n",
    "        x_std = df_temp[\"axis1\"].std()\n",
    "        y_std = df_temp[\"axis2\"].std()\n",
    "        z_std = df_temp[\"axis3\"].std()\n",
    "        \n",
    "        \n",
    "        # avg absolute diff\n",
    "        x_aad = (df_temp[\"axis1\"] - df_temp[\"axis1\"].mean()).abs().mean()\n",
    "        y_aad = (df_temp[\"axis2\"] - df_temp[\"axis2\"].mean()).abs().mean()\n",
    "        z_aad = (df_temp[\"axis3\"] - df_temp[\"axis3\"].mean()).abs().mean()\n",
    "\n",
    "                                                 \n",
    "        # min\n",
    "        x_min = df_temp[\"axis1\"].min()\n",
    "        y_min = df_temp[\"axis2\"].min()\n",
    "        z_min = df_temp[\"axis3\"].min()\n",
    "\n",
    "        # max\n",
    "        x_max = df_temp[\"axis1\"].max()\n",
    "        y_max = df_temp[\"axis2\"].max()\n",
    "        z_max = df_temp[\"axis3\"].max()\n",
    "\n",
    "        # max-min diff\n",
    "        x_maxmin_diff = x_max - x_min\n",
    "        y_maxmin_diff = y_max - y_min\n",
    "        z_maxmin_diff = z_max - z_min\n",
    "\n",
    "        # median\n",
    "        x_median = df_temp[\"axis1\"].median()\n",
    "        y_median = df_temp[\"axis2\"].median()\n",
    "        z_median = df_temp[\"axis3\"].median()\n",
    "        steps = df_temp[\"steps\"].median()\n",
    "        inclineStanding = df_temp[\"inclineStanding\"].median()\n",
    "        inclineSitting = df_temp[\"inclineSitting\"].median()\n",
    "        inclineLying = df_temp[\"inclineLying\"].median()\n",
    "        \n",
    "        # median abs dev\n",
    "        x_mad = (df_temp[\"axis1\"] - df_temp[\"axis1\"].median()).abs().median()\n",
    "        y_mad = (df_temp[\"axis2\"] - df_temp[\"axis2\"].median()).abs().median()\n",
    "        z_mad = (df_temp[\"axis3\"] - df_temp[\"axis3\"].median()).abs().median()\n",
    "\n",
    "        # interquartile range\n",
    "        x_IQR = (df_temp[\"axis1\"].quantile(0.75) - df_temp[\"axis1\"].quantile(0.25))\n",
    "        y_IQR = (df_temp[\"axis2\"].quantile(0.75) - df_temp[\"axis2\"].quantile(0.25))\n",
    "        z_IQR = (df_temp[\"axis3\"].quantile(0.75) - df_temp[\"axis3\"].quantile(0.25))\n",
    "\n",
    "        # negtive count\n",
    "        x_neg_count = (df_temp[\"axis1\"] < 0).sum().sum()\n",
    "        y_neg_count = (df_temp[\"axis2\"] < 0).sum().sum()\n",
    "        z_neg_count = (df_temp[\"axis3\"] < 0).sum().sum()\n",
    "\n",
    "        # positive count\n",
    "        x_pos_count = (df_temp[\"axis1\"] > 0).sum().sum()\n",
    "        y_pos_count = (df_temp[\"axis2\"] > 0).sum().sum()\n",
    "        z_pos_count = (df_temp[\"axis3\"] > 0).sum().sum()\n",
    "\n",
    "        # values above mean\n",
    "        x_above_mean = (df_temp[\"axis1\"] > df_temp[\"axis1\"].mean()).sum().sum()\n",
    "        y_above_mean = (df_temp[\"axis2\"] > df_temp[\"axis2\"].mean()).sum().sum()\n",
    "        z_above_mean = (df_temp[\"axis3\"] > df_temp[\"axis3\"].mean()).sum().sum()\n",
    "\n",
    "        # number of peaks\n",
    "        x_peak_count = len(find_peaks(df_temp[\"axis1\"])[0])\n",
    "        y_peak_count = len(find_peaks(df_temp[\"axis2\"])[0])\n",
    "        z_peak_count = len(find_peaks(df_temp[\"axis3\"])[0])\n",
    "\n",
    "        # skewness\n",
    "        x_skewness = stats.skew(df_temp[\"axis1\"])\n",
    "        y_skewness = stats.skew(df_temp[\"axis2\"])\n",
    "        z_skewness = stats.skew(df_temp[\"axis3\"])\n",
    "\n",
    "        # kurtosis\n",
    "        x_kurtosis = stats.kurtosis(df_temp[\"axis1\"])\n",
    "        y_kurtosis = stats.kurtosis(df_temp[\"axis2\"])\n",
    "        z_kurtosis = stats.kurtosis(df_temp[\"axis3\"])\n",
    "\n",
    "        # energy\n",
    "        x_energy = ((df_temp[\"axis1\"] **2) / 100).sum()\n",
    "        y_energy = ((df_temp[\"axis2\"] **2) / 100).sum()\n",
    "        z_energy = ((df_temp[\"axis3\"] **2) / 100).sum()\n",
    "\n",
    "        # avg resultant\n",
    "        avg_result_accl = ((df_temp[\"axis1\"] ** 2 + df_temp[\"axis2\"] ** 2 + df_temp[\"axis3\"] ** 2) ** 0.5).mean()\n",
    "\n",
    "        # signal magnitude area\n",
    "        sma = (df_temp[\"axis1\"].abs() / 100).sum() +(df_temp[\"axis2\"].abs() / 100).sum() + (df_temp[\"axis3\"].abs() / 100).sum()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        acc_summary = []\n",
    "        acc_summary.extend([x_mean , y_mean, z_mean, x_std, y_std, z_std, x_aad, y_aad, z_aad, x_min, y_min, z_min, x_max, y_max, z_max, \n",
    "                            x_maxmin_diff, y_maxmin_diff, z_maxmin_diff, x_median, y_median, z_median, x_mad, y_mad, z_mad, x_IQR, y_IQR, z_IQR,\n",
    "                            x_neg_count, y_neg_count, z_neg_count, x_pos_count, y_pos_count, z_pos_count,x_above_mean, y_above_mean, z_above_mean,\n",
    "                            x_peak_count, y_peak_count, z_peak_count, x_skewness, y_skewness, z_skewness, x_kurtosis, y_kurtosis, z_kurtosis, x_energy,\n",
    "                            y_energy, z_energy, avg_result_accl, sma, steps, inclineStanding, inclineSitting, inclineLying])\n",
    "        \n",
    "\n",
    "        features = cgm_summary\n",
    "        features.extend(acc_summary)\n",
    "\n",
    "        X_train_temp = pd.DataFrame([features], columns = [\"mean\", \"median\",\"minimum\", \"maximum\",\"first_quartile\", \"third_quartile\",\n",
    "                                                              \"LBGI\", \"HBGI\", \"ADRR\",\"GMI\", \"J_index\", \"eA1c\", \"interdaysd\",\n",
    "                                                              \"cgm_interdaycv\", \n",
    "                                                              \"cgm_TOR\", \"cgm_TIR\",\n",
    "                                                              \"cgm_POR\",\n",
    "                                                              \"x_mean\" , \"y_mean\", \"z_mean\", \"x_std\", \"y_std\", \"z_std\", \"x_aad\", \"y_aad\", \"z_aad\", \"x_min\", \"y_min\", \"z_min\", \"x_max\", \"y_max\", \"z_max\", \n",
    "                                                              \"x_maxmin_diff\", \"y_maxmin_diff\", \"z_maxmin_diff\", \"x_median\", \"y_median\", \"z_median\", \"x_mad\", \"y_mad\", \"z_mad\", \"x_IQR\", \"y_IQR\", \"z_IQR\",\n",
    "                                                              \"x_neg_count\", \"y_neg_count\", \"z_neg_count\", \"x_pos_count\", \"y_pos_count\", \"z_pos_count\",\"x_above_mean\", \"y_above_mean\", \"z_above_mean\",\n",
    "                                                              \"x_peak_count\", \"y_peak_count\", \"z_peak_count\", \"x_skewness\", \"y_skewness\", \"z_skewness\", \"x_kurtosis\", \"y_kurtosis\", \"z_kurtosis\", \"x_energy\",\n",
    "                                                              \"y_energy\", \"z_energy\", \"avg_result_accl\", \"sma\", \"steps\", \"inclineStanding\", \"inclineSitting\", \"inclineLying\"])\n",
    "\n",
    "        \n",
    "        X_train = pd.concat([X_train, X_train_temp], ignore_index=True)\n",
    "        \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda292a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_statistical_measures_gl(x_list):\n",
    "    X_train = pd.DataFrame()\n",
    "\n",
    "    for df_temp in x_list:\n",
    "        cgm_summary = list(cgm.summary(df_temp))\n",
    "        cgm_LBGI = cgm.LBGI(df_temp)\n",
    "        cgm_HBGI = cgm.HBGI(df_temp)\n",
    "        cgm_ADRR = cgm.ADRR(df_temp)\n",
    "        cgm_GMI = cgm.GMI(df_temp)\n",
    "        cgm_J_index = cgm.J_index(df_temp)\n",
    "        cgm_eA1c = cgm.eA1c(df_temp)\n",
    "        cgm_interdaysd = cgm.interdaysd(df_temp)\n",
    "        cgm_interdaycv = cgm.interdaycv(df_temp)\n",
    "        cgm_TOR = cgm.TOR(df_temp, sd=1, sr=15)\n",
    "        cgm_TIR = cgm.TIR(df_temp, sd=1, sr=15)\n",
    "        cgm_POR = cgm.POR(df_temp, sd=1, sr=15)\n",
    "\n",
    "        \n",
    "        cgm_summary.append(cgm_LBGI)\n",
    "        cgm_summary.append(cgm_HBGI)\n",
    "        cgm_summary.append(cgm_ADRR)\n",
    "        cgm_summary.append(cgm_GMI)\n",
    "        cgm_summary.append(cgm_J_index)\n",
    "        cgm_summary.append(cgm_eA1c)\n",
    "        cgm_summary.append(cgm_interdaysd)\n",
    "        cgm_summary.append(cgm_interdaycv)\n",
    "        cgm_summary.append(cgm_TOR)\n",
    "        cgm_summary.append(cgm_TIR)\n",
    "        cgm_summary.append(cgm_POR)\n",
    "\n",
    "\n",
    "        features = cgm_summary\n",
    "\n",
    "        X_train_temp = pd.DataFrame([cgm_summary], columns = [\"mean\", \"median\",\"minimum\", \"maximum\",\"first_quartile\", \"third_quartile\",\n",
    "                                                              \"LBGI\", \"HBGI\", \"ADRR\",\"GMI\", \"J_index\", \"eA1c\", \"interdaysd\",\n",
    "                                                              \"cgm_interdaycv\", \n",
    "                                                              \"cgm_TOR\", \"cgm_TIR\",\n",
    "                                                              \"cgm_POR\"])\n",
    "\n",
    "        \n",
    "        X_train = pd.concat([X_train, X_train_temp], ignore_index=True)\n",
    "        \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a60fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_statistical_measures_acc(x_list):\n",
    "    X_train = pd.DataFrame()\n",
    "\n",
    "    for df_temp in x_list:\n",
    "\n",
    "        # mean\n",
    "        x_mean = df_temp[\"axis1\"].mean()\n",
    "        y_mean = df_temp[\"axis2\"].mean()\n",
    "        z_mean = df_temp[\"axis3\"].mean()\n",
    "\n",
    "        # std dev\n",
    "        x_std = df_temp[\"axis1\"].std()\n",
    "        y_std = df_temp[\"axis2\"].std()\n",
    "        z_std = df_temp[\"axis3\"].std()\n",
    "        \n",
    "        \n",
    "        # avg absolute diff\n",
    "        x_aad = (df_temp[\"axis1\"] - df_temp[\"axis1\"].mean()).abs().mean()\n",
    "        y_aad = (df_temp[\"axis2\"] - df_temp[\"axis2\"].mean()).abs().mean()\n",
    "        z_aad = (df_temp[\"axis3\"] - df_temp[\"axis3\"].mean()).abs().mean()\n",
    "\n",
    "                                                 \n",
    "        # min\n",
    "        x_min = df_temp[\"axis1\"].min()\n",
    "        y_min = df_temp[\"axis2\"].min()\n",
    "        z_min = df_temp[\"axis3\"].min()\n",
    "\n",
    "        # max\n",
    "        x_max = df_temp[\"axis1\"].max()\n",
    "        y_max = df_temp[\"axis2\"].max()\n",
    "        z_max = df_temp[\"axis3\"].max()\n",
    "\n",
    "        # max-min diff\n",
    "        x_maxmin_diff = x_max - x_min\n",
    "        y_maxmin_diff = y_max - y_min\n",
    "        z_maxmin_diff = z_max - z_min\n",
    "\n",
    "        # median\n",
    "        x_median = df_temp[\"axis1\"].median()\n",
    "        y_median = df_temp[\"axis2\"].median()\n",
    "        z_median = df_temp[\"axis3\"].median()\n",
    "        steps = df_temp[\"steps\"].median()\n",
    "        inclineStanding = df_temp[\"inclineStanding\"].median()\n",
    "        inclineSitting = df_temp[\"inclineSitting\"].median()\n",
    "        inclineLying = df_temp[\"inclineLying\"].median()\n",
    "        \n",
    "        # median abs dev\n",
    "        x_mad = (df_temp[\"axis1\"] - df_temp[\"axis1\"].median()).abs().median()\n",
    "        y_mad = (df_temp[\"axis2\"] - df_temp[\"axis2\"].median()).abs().median()\n",
    "        z_mad = (df_temp[\"axis3\"] - df_temp[\"axis3\"].median()).abs().median()\n",
    "\n",
    "        # interquartile range\n",
    "        x_IQR = (df_temp[\"axis1\"].quantile(0.75) - df_temp[\"axis1\"].quantile(0.25))\n",
    "        y_IQR = (df_temp[\"axis2\"].quantile(0.75) - df_temp[\"axis2\"].quantile(0.25))\n",
    "        z_IQR = (df_temp[\"axis3\"].quantile(0.75) - df_temp[\"axis3\"].quantile(0.25))\n",
    "\n",
    "        # negtive count\n",
    "        x_neg_count = (df_temp[\"axis1\"] < 0).sum().sum()\n",
    "        y_neg_count = (df_temp[\"axis2\"] < 0).sum().sum()\n",
    "        z_neg_count = (df_temp[\"axis3\"] < 0).sum().sum()\n",
    "\n",
    "        # positive count\n",
    "        x_pos_count = (df_temp[\"axis1\"] > 0).sum().sum()\n",
    "        y_pos_count = (df_temp[\"axis2\"] > 0).sum().sum()\n",
    "        z_pos_count = (df_temp[\"axis3\"] > 0).sum().sum()\n",
    "\n",
    "        # values above mean\n",
    "        x_above_mean = (df_temp[\"axis1\"] > df_temp[\"axis1\"].mean()).sum().sum()\n",
    "        y_above_mean = (df_temp[\"axis2\"] > df_temp[\"axis2\"].mean()).sum().sum()\n",
    "        z_above_mean = (df_temp[\"axis3\"] > df_temp[\"axis3\"].mean()).sum().sum()\n",
    "\n",
    "        # number of peaks\n",
    "        x_peak_count = len(find_peaks(df_temp[\"axis1\"])[0])\n",
    "        y_peak_count = len(find_peaks(df_temp[\"axis2\"])[0])\n",
    "        z_peak_count = len(find_peaks(df_temp[\"axis3\"])[0])\n",
    "\n",
    "        # skewness\n",
    "        x_skewness = stats.skew(df_temp[\"axis1\"])\n",
    "        y_skewness = stats.skew(df_temp[\"axis2\"])\n",
    "        z_skewness = stats.skew(df_temp[\"axis3\"])\n",
    "\n",
    "        # kurtosis\n",
    "        x_kurtosis = stats.kurtosis(df_temp[\"axis1\"])\n",
    "        y_kurtosis = stats.kurtosis(df_temp[\"axis2\"])\n",
    "        z_kurtosis = stats.kurtosis(df_temp[\"axis3\"])\n",
    "\n",
    "        # energy\n",
    "        x_energy = ((df_temp[\"axis1\"] **2) / 100).sum()\n",
    "        y_energy = ((df_temp[\"axis2\"] **2) / 100).sum()\n",
    "        z_energy = ((df_temp[\"axis3\"] **2) / 100).sum()\n",
    "\n",
    "        # avg resultant\n",
    "        avg_result_accl = ((df_temp[\"axis1\"] ** 2 + df_temp[\"axis2\"] ** 2 + df_temp[\"axis3\"] ** 2) ** 0.5).mean()\n",
    "\n",
    "        # signal magnitude area\n",
    "        sma = (df_temp[\"axis1\"].abs() / 100).sum() +(df_temp[\"axis2\"].abs() / 100).sum() + (df_temp[\"axis3\"].abs() / 100).sum()\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        acc_summary = []\n",
    "        acc_summary.extend([x_mean , y_mean, z_mean, x_std, y_std, z_std, x_aad, y_aad, z_aad, x_min, y_min, z_min, x_max, y_max, z_max, \n",
    "                            x_maxmin_diff, y_maxmin_diff, z_maxmin_diff, x_median, y_median, z_median, x_mad, y_mad, z_mad, x_IQR, y_IQR, z_IQR,\n",
    "                            x_neg_count, y_neg_count, z_neg_count, x_pos_count, y_pos_count, z_pos_count,x_above_mean, y_above_mean, z_above_mean,\n",
    "                            x_peak_count, y_peak_count, z_peak_count, x_skewness, y_skewness, z_skewness, x_kurtosis, y_kurtosis, z_kurtosis, x_energy,\n",
    "                            y_energy, z_energy, avg_result_accl, sma, steps, inclineStanding, inclineSitting, inclineLying])\n",
    "        \n",
    "\n",
    "\n",
    "        X_train_temp = pd.DataFrame([acc_summary], columns = [\"x_mean\" , \"y_mean\", \"z_mean\", \"x_std\", \"y_std\", \"z_std\", \"x_aad\", \"y_aad\", \"z_aad\", \"x_min\", \"y_min\", \"z_min\", \"x_max\", \"y_max\", \"z_max\", \n",
    "                                                              \"x_maxmin_diff\", \"y_maxmin_diff\", \"z_maxmin_diff\", \"x_median\", \"y_median\", \"z_median\", \"x_mad\", \"y_mad\", \"z_mad\", \"x_IQR\", \"y_IQR\", \"z_IQR\",\n",
    "                                                              \"x_neg_count\", \"y_neg_count\", \"z_neg_count\", \"x_pos_count\", \"y_pos_count\", \"z_pos_count\",\"x_above_mean\", \"y_above_mean\", \"z_above_mean\",\n",
    "                                                              \"x_peak_count\", \"y_peak_count\", \"z_peak_count\", \"x_skewness\", \"y_skewness\", \"z_skewness\", \"x_kurtosis\", \"y_kurtosis\", \"z_kurtosis\", \"x_energy\",\n",
    "                                                              \"y_energy\", \"z_energy\", \"avg_result_accl\", \"sma\", \"steps\", \"inclineStanding\", \"inclineSitting\", \"inclineLying\"])\n",
    "\n",
    "        \n",
    "        X_train = pd.concat([X_train, X_train_temp], ignore_index=True)\n",
    "        \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_statistical_measures_gl_acc_ml(x_list):\n",
    "    X_train = pd.DataFrame()\n",
    "\n",
    "    for df_temp in x_list:\n",
    "        cgm_summary = list(cgm.summary(df_temp))\n",
    "        cgm_J_index = cgm.J_index(df_temp)\n",
    "        cgm_interdaycv = cgm.interdaycv(df_temp)\n",
    "\n",
    "        cgm_summary.append(cgm_J_index)\n",
    "        cgm_summary.append(cgm_interdaycv)\n",
    "\n",
    "\n",
    "        z_mean = df_temp[\"axis3\"].mean()\n",
    "        y_max = df_temp[\"axis2\"].max()\n",
    "        z_energy = ((df_temp[\"axis3\"] ** 2) / 100).sum()\n",
    "\n",
    "        acc_summary = []\n",
    "        acc_summary.extend(\n",
    "            [z_mean, y_max, z_energy])\n",
    "\n",
    "        features = cgm_summary\n",
    "        features.extend(acc_summary)\n",
    "\n",
    "        X_train_temp = pd.DataFrame([features],\n",
    "                                    columns=[\"mean\", \"median\", \"minimum\", \"maximum\", \"first_quartile\", \"third_quartile\",\n",
    "                                             \"J_index\", \"cgm_interdaycv\", \"z_mean\", \"y_max\", \"z_energy\"])\n",
    "\n",
    "        X_train = pd.concat([X_train, X_train_temp], ignore_index=True)\n",
    "\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609033e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_statistical_measures_acc_ml(x_list):\n",
    "    X_train = pd.DataFrame()\n",
    "\n",
    "    for df_temp in x_list:\n",
    "        # mean\n",
    "        z_mean = df_temp[\"axis3\"].mean()\n",
    "        y_max = df_temp[\"axis2\"].max()\n",
    "        z_energy = ((df_temp[\"axis3\"] ** 2) / 100).sum()\n",
    "\n",
    "\n",
    "        acc_summary = []\n",
    "        acc_summary.extend(\n",
    "            [z_mean, y_max, z_energy])\n",
    "\n",
    "        X_train_temp = pd.DataFrame([acc_summary],\n",
    "                                    columns=[\"z_mean\", \"y_max\", \"z_energy\"])\n",
    "\n",
    "        X_train = pd.concat([X_train, X_train_temp], ignore_index=True)\n",
    "\n",
    "    return X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_statistical_measures_gl_ml(x_list):\n",
    "    X_train = pd.DataFrame()\n",
    "\n",
    "    for df_temp in x_list:\n",
    "        cgm_summary = list(cgm.summary(df_temp))\n",
    "        cgm_LBGI = cgm.LBGI(df_temp)\n",
    "        cgm_HBGI = cgm.HBGI(df_temp)\n",
    "        cgm_ADRR = cgm.ADRR(df_temp)\n",
    "        cgm_GMI = cgm.GMI(df_temp)\n",
    "        cgm_J_index = cgm.J_index(df_temp)\n",
    "        cgm_eA1c = cgm.eA1c(df_temp)\n",
    "        cgm_interdaysd = cgm.interdaysd(df_temp)\n",
    "        cgm_interdaycv = cgm.interdaycv(df_temp)\n",
    "        cgm_TOR = cgm.TOR(df_temp, sd=1, sr=15)\n",
    "        cgm_TIR = cgm.TIR(df_temp, sd=1, sr=15)\n",
    "        cgm_POR = cgm.POR(df_temp, sd=1, sr=15)\n",
    "\n",
    "\n",
    "        cgm_summary.append(cgm_LBGI)\n",
    "        cgm_summary.append(cgm_HBGI)\n",
    "        cgm_summary.append(cgm_ADRR)\n",
    "        cgm_summary.append(cgm_GMI)\n",
    "        cgm_summary.append(cgm_J_index)\n",
    "        cgm_summary.append(cgm_eA1c)\n",
    "        cgm_summary.append(cgm_interdaysd)\n",
    "        cgm_summary.append(cgm_interdaycv)\n",
    "        cgm_summary.append(cgm_TOR)\n",
    "        cgm_summary.append(cgm_TIR)\n",
    "        cgm_summary.append(cgm_POR)\n",
    "\n",
    "        X_train_temp = pd.DataFrame([cgm_summary],\n",
    "                                    columns=[\"mean\", \"median\", \"minimum\", \"maximum\", \"first_quartile\", \"third_quartile\",\n",
    "                                             \"LBGI\", \"HBGI\", \"ADRR\", \"GMI\", \"J_index\", \"eA1c\", \"interdaysd\",\n",
    "                                             \"cgm_interdaycv\",\n",
    "                                             \"cgm_TOR\", \"cgm_TIR\",\n",
    "                                             \"cgm_POR\"])\n",
    "\n",
    "        X_train = pd.concat([X_train, X_train_temp], ignore_index=True)\n",
    "\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a26e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = feat_statistical_measures_gl_acc(x_list_test)\n",
    "\n",
    "X_train = feat_statistical_measures_gl_acc(x_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d91783",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = feat_statistical_measures_gl_ml( x_list_test)\n",
    "\n",
    "X_train = feat_statistical_measures_gl_ml(x_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a0926b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test = feat_statistical_measures_gl_acc_ml( x_list_test)\n",
    "\n",
    "X_train = feat_statistical_measures_gl_acc_ml(x_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c129a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = feat_statistical_measures_acc_ml( x_list_test)\n",
    "\n",
    "X_train = feat_statistical_measures_acc_ml(x_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e88bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac77d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"ML_data/eval_X_test_acc.csv\", sep='\\t')\n",
    "X_train.to_csv(\"ML_data/eval_X_train_acc.csv\", sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aedccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e21aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float(input_string):\n",
    "    if input_string == \"fasting\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_float = np.vectorize(to_float)\n",
    "y_train_float = func_float(y_train)\n",
    "y_test_float = func_float(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdd22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ML_data/y_train_eval_acc.npy', y_train_float)\n",
    "np.save('ML_data/y_test_eval_acc.npy', y_test_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = [\"cgm_interdaycv\", \"J_index\", \"maximum\", \"z_mean\", \"y_max\", \"z_energy\"]\n",
    "\n",
    "X_test = X_test[features_to_keep] \n",
    "X_train = X_train[features_to_keep] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9362f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = [\"cgm_interdaycv\", \"J_index\", \"maximum\"]\n",
    "\n",
    "X_test = X_test[features_to_keep] \n",
    "X_train = X_train[features_to_keep] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = [\"z_mean\", \"y_max\", \"z_energy\"]\n",
    "\n",
    "X_test = X_test[features_to_keep] \n",
    "X_train = X_train[features_to_keep] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b5cd8",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0dbd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfe = RFE(RandomForestRegressor(n_estimators=500, random_state=1), n_features_to_select=4)\n",
    "fit = rfe.fit(X_train, y_train_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54396163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "rfe = RFE(DecisionTreeClassifier(), n_features_to_select=6)\n",
    "fit = rfe.fit(X_train, y_train_float)\n",
    "# report selected features\n",
    "print('Selected Features:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995543e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f8f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = X_train.columns.values[0:-1]\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e61826",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['y_max'].corr(X_train['z_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b5915",
   "metadata": {},
   "source": [
    "## Balancing\n",
    "\n",
    "https://imbalanced-learn.org/stable/over_sampling.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = final_df.drop([\"Time\", \"time\", \"Day\"], axis=1)\n",
    "\n",
    "balanced_df.phase = pd.Categorical(balanced_df.phase)\n",
    "balanced_df['phase'] = balanced_df.phase.cat.codes\n",
    "\n",
    "balanced_df.label = pd.Categorical(balanced_df.label)\n",
    "balanced_df['label'] = balanced_df.label.cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('eval_X_test.csv', sep='\\t')\n",
    "X_train = pd.read_csv('eval_X_train.csv', sep='\\t')\n",
    "\n",
    "X_test = X_test.drop([\"Unnamed: 0\"], axis=1)\n",
    "X_train = X_train.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_float = np.load('ML_data/y_train_eval.npy')\n",
    "y_test_float = np.load('ML_data/y_test_eval.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44487f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(collections.Counter(y_test_float).items()))\n",
    "print(sorted(collections.Counter(y_train_float).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae770cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180eb0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "smote_tomek = SMOTETomek(random_state=0)\n",
    "X_test_resampled, y_test_resampled = smote_tomek.fit_resample(X_test, y_test_float)\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33392fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(collections.Counter(y_test_resampled).items()))\n",
    "print(sorted(collections.Counter(y_train_resampled).items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed80b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1aa1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a4fbd",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b232558",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train_resampled)\n",
    "\n",
    "X_train_data_lr = pd.DataFrame(scaler.transform(X_train_resampled), index=X_train_resampled.index, columns=X_train_resampled.columns)\n",
    "X_test_data_lr = pd.DataFrame(scaler.transform(X_test_resampled), index=X_test_resampled.index, columns=X_test_resampled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d80d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train_resampled)\n",
    "X_train_data_lr = scaler.transform(X_train_resampled)\n",
    "X_test_data_lr = scaler.transform(X_test_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ba677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model\n",
    "lr = LogisticRegression(penalty='l2', solver='liblinear', max_iter=157, C=0.97)\n",
    "lr.fit(X_train_data_lr, y_train_resampled)\n",
    "y_pred = lr.predict(X_test_data_lr)\n",
    "y_pred = smoothing(y_pred)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_resampled, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398fe6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_resampled, y_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aea099",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d44eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression(\n",
    "    random_state = 1,\n",
    "    penalty = 'l2'\n",
    ")\n",
    "#estimator.fit(X_train_data_lr, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbae578",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = range(100, 200)\n",
    "solver = ['lbfgs', 'newton-cg', 'liblinear']\n",
    "warm_start = [True, False]\n",
    "C = np.arange(0, 1, 0.01)\n",
    "random_grid ={\n",
    "    'max_iter' : max_iter,\n",
    "    'warm_start' : warm_start,\n",
    "    'solver' : solver,\n",
    "    'C' : C,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_estimator = RandomizedSearchCV(estimator = estimator,\n",
    "                                   param_distributions = random_grid,\n",
    "                                   n_iter = 100,\n",
    "                                   scoring = 'accuracy',\n",
    "                                   n_jobs = -1,\n",
    "                                   verbose = 1, \n",
    "                                   random_state = 1,\n",
    "                                  )\n",
    "\n",
    "random_estimator.fit(X_train_data_lr, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f8cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_estimator.best_params_\n",
    "\n",
    "best_estimator = random_estimator.best_estimator_\n",
    "\n",
    "best_estimator.fit(X_train_data_lr, y_train_resampled)\n",
    "\n",
    "pred = best_estimator.predict(X_test_data_lr)\n",
    "\n",
    "accuracy_score(y_test_resampled,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7214cf1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_smoothed = smoothing(pred)\n",
    "accuracy_score(y_test_resampled,y_pred_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test_resampled, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de103f",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch_table_plot(grid_clf, param_name,\n",
    "                          num_results=15,\n",
    "                          negative=True,\n",
    "                          graph=True,\n",
    "                          display_all_params=True):\n",
    "\n",
    "    '''Display grid search results\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "\n",
    "    grid_clf           the estimator resulting from a grid search\n",
    "                       for example: grid_clf = GridSearchCV( ...\n",
    "\n",
    "    param_name         a string with the name of the parameter being tested\n",
    "\n",
    "    num_results        an integer indicating the number of results to display\n",
    "                       Default: 15\n",
    "\n",
    "    negative           boolean: should the sign of the score be reversed?\n",
    "                       scoring = 'neg_log_loss', for instance\n",
    "                       Default: True\n",
    "\n",
    "    graph              boolean: should a graph be produced?\n",
    "                       non-numeric parameters (True/False, None) don't graph well\n",
    "                       Default: True\n",
    "\n",
    "    display_all_params boolean: should we print out all of the parameters, not just the ones searched for?\n",
    "                       Default: True\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "\n",
    "    GridSearch_table_plot(grid_clf, \"min_samples_leaf\")\n",
    "\n",
    "                          '''\n",
    "    from matplotlib      import pyplot as plt\n",
    "    from IPython.display import display\n",
    "    import pandas as pd\n",
    "\n",
    "    clf = grid_clf.best_estimator_\n",
    "    clf_params = grid_clf.best_params_\n",
    "    if negative:\n",
    "        clf_score = -grid_clf.best_score_\n",
    "    else:\n",
    "        clf_score = grid_clf.best_score_\n",
    "    clf_stdev = grid_clf.cv_results_['std_test_score'][grid_clf.best_index_]\n",
    "    cv_results = grid_clf.cv_results_\n",
    "\n",
    "    print(\"best parameters: {}\".format(clf_params))\n",
    "    print(\"best score:      {:0.5f} (+/-{:0.5f})\".format(clf_score, clf_stdev))\n",
    "    if display_all_params:\n",
    "        import pprint\n",
    "        pprint.pprint(clf.get_params())\n",
    "\n",
    "    # pick out the best results\n",
    "    # =========================\n",
    "    scores_df = pd.DataFrame(cv_results).sort_values(by='rank_test_score')\n",
    "\n",
    "    best_row = scores_df.iloc[0, :]\n",
    "    if negative:\n",
    "        best_mean = -best_row['mean_test_score']\n",
    "    else:\n",
    "        best_mean = best_row['mean_test_score']\n",
    "    best_stdev = best_row['std_test_score']\n",
    "    best_param = best_row['param_' + param_name]\n",
    "\n",
    "    # display the top 'num_results' results\n",
    "    # =====================================\n",
    "    display(pd.DataFrame(cv_results) \\\n",
    "            .sort_values(by='rank_test_score').head(num_results))\n",
    "\n",
    "    # plot the results\n",
    "    # ================\n",
    "    scores_df = scores_df.sort_values(by='param_' + param_name)\n",
    "\n",
    "    if negative:\n",
    "        means = -scores_df['mean_test_score']\n",
    "    else:\n",
    "        means = scores_df['mean_test_score']\n",
    "    stds = scores_df['std_test_score']\n",
    "    params = scores_df['param_' + param_name]\n",
    "\n",
    "    # plot\n",
    "    if graph:\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.errorbar(params, means, yerr=stds)\n",
    "\n",
    "        plt.axhline(y=best_mean + best_stdev, color='red')\n",
    "        plt.axhline(y=best_mean - best_stdev, color='red')\n",
    "        plt.plot(best_param, best_mean, 'or')\n",
    "\n",
    "        plt.title(param_name + \" vs Score\\nBest Score {:0.5f}\".format(clf_score))\n",
    "        plt.xlabel(param_name)\n",
    "        plt.ylabel('Score')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddba2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch_table_plot(random_estimator, \"C\", negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e397bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_estimator.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d20ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84014479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_resampled, y_pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80577d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ML_data/models_ML/gl/ML_LR_adapt_scaler.pkl','wb') as f:\n",
    "    pickle.dump(lr,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('LR_random_estimator.pkl','wb') as f:\n",
    "    pickle.dump(random_estimator,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(scaler, open(\"ML_data/models_ML/gl/ML_scaler_adapt.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41d310",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1bdfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_clf = svm.SVC(C=1000.0, kernel='rbf')\n",
    "svm_clf.fit(X_train_data_lr, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d8e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_clf.predict(X_test_data_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a4b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test_resampled, y_pred))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa916d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_resampled, smoothing(y_pred))\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bef8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "# Fits the explainer\n",
    "explainer = shap.Explainer(svm_clf.predict, X_test_data_lr)\n",
    "# Calculates the SHAP values - It takes some time\n",
    "shap_values = explainer(X_test_data_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5560bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ML_data/models_ML/gl/ML_SVM_adapt.pkl','wb') as f:\n",
    "    pickle.dump(svm_clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e24eef",
   "metadata": {},
   "source": [
    "### Random CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb2b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel': ['rbf', 'sigmoid', 'poly'],\n",
    "             'C': [0.1, 1.0, 100.0, 1000.0],\n",
    "             'gamma': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],}#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de60282",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_estimator = RandomizedSearchCV(estimator = svm_clf,\n",
    "                                   param_distributions = parameters,\n",
    "                                   cv = 5,\n",
    "                                   n_iter = 100,\n",
    "                                   scoring = 'accuracy',\n",
    "                                   n_jobs = -1,\n",
    "                                   verbose = 1, \n",
    "                                   random_state = 1,\n",
    "                                  )\n",
    "\n",
    "random_estimator.fit(X_train_data_lr, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3455fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_estimator.best_params_\n",
    "\n",
    "best_estimator = random_estimator.best_estimator_\n",
    "\n",
    "best_estimator.fit(X_train_data_lr, y_train_resampled)\n",
    "\n",
    "pred = best_estimator.predict(X_test_data_lr)\n",
    "\n",
    "accuracy_score(pred, y_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5648960",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_smoothed = smoothing(pred)\n",
    "accuracy_score(y_pred_smoothed, y_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c357cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch_table_plot(random_estimator, \"gamma\", negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d37bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test_resampled, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235a03b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5ad8073",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sdg_clf = SGDClassifier(loss=\"log\", penalty=\"l2\", alpha = 0.001, learning_rate='optimal')\n",
    "sdg_clf.fit(X_train_data_lr, y_train_resampled)\n",
    "y_pred = sdg_clf.predict(X_test_data_lr)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_resampled, smoothing(y_pred)))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled,  smoothing(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b02923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_resampled, smoothing(y_pred))\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a736c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ML_data/models_ML/gl/ML_SDG_adapt.pkl','wb') as f:\n",
    "    pickle.dump(sdg_clf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6149f24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set search parameters\n",
    "loss = ['hinge', 'log_loss', 'log', 'modified_huber', 'perceptron', 'squared_error']\n",
    "penalty = ['l2','l1','elasticnet']\n",
    "learning_rate = ['constant','optimal','invscaling']\n",
    "alpha = [0.0001, 0.001, 0.01, 0.1]\n",
    "random_grid = {\n",
    "    'loss': loss,\n",
    "    'penalty': penalty,\n",
    "    'alpha': alpha,\n",
    "    'learning_rate': learning_rate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3890a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier() \n",
    "sgd_random = RandomizedSearchCV(estimator = sgd, random_state = 42,n_jobs = -1,param_distributions = random_grid,n_iter = 100, cv=3,verbose = 2)\n",
    "sgd_random.fit(X_train_data_lr, y_train_resampled)\n",
    "sgd_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_random.best_params_\n",
    "\n",
    "best_estimator = sgd_random.best_estimator_\n",
    "\n",
    "best_estimator.fit(X_train_data_lr, y_train_resampled)\n",
    "\n",
    "pred = best_estimator.predict(X_test_data_lr)\n",
    "\n",
    "accuracy_score(pred, y_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch_table_plot(sgd_random, \"loss\", negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f99eb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85393adf",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b2ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=13,weights=\"distance\", metric=\"manhattan\" )\n",
    "#model = KNeighborsClassifier( )\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(X_train_data_lr,y_train_resampled)\n",
    "y_pred = model.predict(X_test_data_lr)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_resampled, smoothing(y_pred)))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled, smoothing(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58087418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_resampled,smoothing(y_pred))\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a758b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ML_data/models_ML/gl/ML_KNN_adapt.pkl','wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df437c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set search parameters\n",
    "n_neighbors = [int(x) for x in np.linspace(start = 1, stop = 100, num = 50)]   \n",
    "weights = ['uniform','distance']\n",
    "metric = ['euclidean','manhattan','chebyshev','minkowski'] \n",
    "random_grid = {\n",
    "    'n_neighbors': n_neighbors,\n",
    "    'weights': weights,\n",
    "    'metric': metric,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c685874",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier() \n",
    "knn_random = RandomizedSearchCV(estimator = knn, random_state = 42,n_jobs = -1,param_distributions = random_grid,n_iter = 100, cv=3,verbose = 2)\n",
    "knn_random.fit(X_train_data_lr, y_train_resampled)\n",
    "knn_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d5e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_random.best_params_\n",
    "\n",
    "best_estimator = knn_random.best_estimator_\n",
    "\n",
    "best_estimator.fit(X_train_data_lr, y_train_resampled)\n",
    "\n",
    "pred = best_estimator.predict(X_test_data_lr)\n",
    "\n",
    "accuracy_score(pred, smoothing(y_test_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d1842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch_table_plot(knn_random, \"metric\", negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6781b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997a9f1",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91127df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=40, random_state=0, max_depth=20, bootstrap=False)\n",
    "regressor.fit(X_train_data_lr, y_train_resampled)\n",
    "y_pred = regressor.predict(X_test_data_lr)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_resampled, smoothing(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fce8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled, smoothing(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2395465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_resampled, smoothing(y_pred))\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d654f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 1, stop = 40, num = 40)] # number of trees in the random forest\n",
    "max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
    "max_depth = [int(x) for x in np.linspace(10, 120, num = 12)] # maximum number of levels allowed in each decision tree\n",
    "min_samples_split = [2, 6, 10] # minimum sample number to split a node\n",
    "min_samples_leaf = [1, 3, 4] # minimum sample number that can be stored in a leaf node\n",
    "bootstrap = [True, False] # method used to sample data points\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "'max_features': max_features,\n",
    "\n",
    "'max_depth': max_depth,\n",
    "\n",
    "'min_samples_split': min_samples_split,\n",
    "\n",
    "'min_samples_leaf': min_samples_leaf,\n",
    "\n",
    "'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e62068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,n_iter = 100, cv = 5, verbose=2, random_state=35, n_jobs = -1)\n",
    "rf_random.fit(X_train_data_lr,y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb4d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_\n",
    "\n",
    "best_estimator = rf_random.best_estimator_\n",
    "\n",
    "best_estimator.fit(X_train_data_lr, y_train_resampled)\n",
    "\n",
    "pred = best_estimator.predict(X_test_data_lr)\n",
    "\n",
    "accuracy_score(pred, y_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccbbdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch_table_plot(rf_random, \"max_depth\", negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ML_data/models_ML/gl/ML_RF_adapt.pkl','wb') as f:\n",
    "    pickle.dump(regressor,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6f803",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d04e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt_clf = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth=20, min_samples_leaf= 100, max_features=\"sqrt\")\n",
    "dt_clf = dt_clf.fit(X_train_data_lr, y_train_resampled)\n",
    "y_pred = dt_clf.predict(X_test_data_lr)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_resampled, smoothing(y_pred)))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled, smoothing(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d9661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_resampled, smoothing(y_pred))\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b658f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "params = {\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 120, num = 12)],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100, 150],\n",
    "    'max_features' : ['auto', 'sqrt'],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22adcb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_random = RandomizedSearchCV(estimator = dt, param_distributions = params,n_iter = 100, cv = 5, verbose=2, random_state=35, n_jobs = -1)\n",
    "dt_random.fit(X_train_data_lr,y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_random.best_params_\n",
    "\n",
    "best_estimator = dt_random.best_estimator_\n",
    "\n",
    "best_estimator.fit(X_train_data_lr, y_train_resampled)\n",
    "\n",
    "pred = best_estimator.predict(X_test_data_lr)\n",
    "\n",
    "accuracy_score(pred, y_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab3551",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch_table_plot(dt_random, \"min_samples_leaf\", negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe3718",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f1fe32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe26c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ML_data/models_ML/gl/ML_DT_adapt.pkl','wb') as f:\n",
    "    pickle.dump(dt_clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed82ad",
   "metadata": {},
   "source": [
    "## Multi-layer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c26079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_clf = MLPClassifier(solver='adam', alpha=0.0001, hidden_layer_sizes=(50, 50, 50), random_state=1)\n",
    "mlp_clf.fit(X_train_data_lr, y_train_resampled)\n",
    "y_pred = mlp_clf.predict(X_test_data_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac119a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test_resampled, smoothing(y_pred)))\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled, smoothing(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06859874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=100)\n",
    "mlp.fit(X_train_data_lr, y_train_resampled)\n",
    "\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5082204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_estimator = RandomizedSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "random_estimator.fit(X_train_data_lr, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7027eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_estimator.best_params_\n",
    "\n",
    "best_estimator = random_estimator.best_estimator_\n",
    "\n",
    "best_estimator.fit(X_train_data_lr, y_train_resampled)\n",
    "\n",
    "pred = best_estimator.predict(X_test_data_lr)\n",
    "\n",
    "accuracy_score(pred, y_test_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearch_table_plot(random_estimator, \"alpha\", negative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3940a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_resampled,smoothing(y_pred))\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test_resampled, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7363854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ML_data/models_ML/gl/ML_MLP_adapt.pkl','wb') as f:\n",
    "    pickle.dump(mlp_clf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_data_lr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868aa54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[1456])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea041db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits the explainer\n",
    "explainer = shap.Explainer(svm_clf.predict, X_test_data_lr)\n",
    "# Calculates the SHAP values - It takes some time\n",
    "shap_values = explainer(X_test_data_lr[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap.summary_plot(shap_values, feature_names=[\"glucose interdaycv\", \"glucose J_index\", \"glucose maximum\", \"acceleration z_mean\", \"acceleration y_max\", \"acceleration z_energy\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
